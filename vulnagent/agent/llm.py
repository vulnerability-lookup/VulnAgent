import getpass

from spade_llm import LLMAgent, LLMProvider  # pyright: ignore[reportMissingImports]

from vulnagent.tools.current_time import current_time_tool
from vulnagent.tools.cwe import cwe_classify_tool, vulnerability_per_cwe_tool
from vulnagent.tools.calculate import math_tool
from vulnagent.tools.severity import severity_tool
from vulnagent.tools.weather import weather_tool


def get_llm_provider(
    model: str = "qwen2.5:7b",
    base_url: str = "http://localhost:11434/v1",
    temperature: float = 0.7,
):
    """
    Returns an LLMProvider configured for Ollama.
    """
    return LLMProvider.create_ollama(
        model=model, base_url=base_url, temperature=temperature
    )


tools = [
    severity_tool,
    cwe_classify_tool,
    vulnerability_per_cwe_tool,
    weather_tool,
    current_time_tool,
    math_tool,
]


system_prompt = (
    "You are a security-focused assistant with access to specialized tools.\n\n"
    "You can use the following tools when appropriate:\n"
    "- classify_cwe: classify a vulnerability description into CWE categories\n"
    "- classify_severity: classify a vulnerability severity\n"
    "- vulnerability_info_by_cwe: retrieve recent vulnerabilities for a given CWE ID\n"
    "- get_current_time, calculate_math, get_weather for general assistance\n\n"
    "Tool usage guidelines:\n"
    "- If the user provides a vulnerability description and asks for classification, "
    "use classify_cwe and/or classify_severity.\n"
    "- If the user asks for recent or known vulnerabilities for a specific CWE "
    "(e.g. 'recent vulnerabilities for CWE-119'), "
    "use vulnerability_info_by_cwe.\n"
    "- Do NOT invent vulnerability data; always use tools for factual vulnerability information.\n\n"
    "Response style:\n"
    "- Be concise and factual.\n"
    "- Assume the audience has security knowledge.\n"
    "- Summarize vulnerabilities briefly (title, short description, affected vendor/product, link).\n"
    "- Avoid unnecessary verbosity or speculation.\n\n"
    "If no tool is relevant, respond directly in plain text."
)


def init_llm_agent(xmpp_server, agent_name="tool_assistant", llm_provider="qwen2.5:7b"):
    """
    Initializes the LLM Agent.

    :param xmpp_server: Address of the XMPP server (default: localhost)
    """
    llm_provider = input("LLM provider to use (default: qwen2.5:7b): ") or llm_provider
    base_url = (
        input("LLM provider base URL (default: http://localhost:11434/v1): ")
        or "http://localhost:11434/v1"
    )
    agent_name = input("Agent name (default: tool_assistant): ") or agent_name

    llm_agent = LLMAgent(
        jid=f"{agent_name}@{xmpp_server}",
        password=getpass.getpass("LLM agent password: "),
        provider=get_llm_provider(model=llm_provider, base_url=base_url),
        system_prompt=system_prompt,
        tools=tools,
    )
    return llm_agent
